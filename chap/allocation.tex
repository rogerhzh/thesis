% Copyright (c) 2014,2016 Casper Ti. Vector
% Public domain.

\chapter{分配优化} \label{chap:allocation}

\section{算法综述}

本章节中，我们将介绍CAPS的优化算法。该优化算法基于上一章节的预测模型，可以针对一个优化目标，在较短时间内生成一个优化CAT分配。同时，该算法还支持不同的优化目标，我们在CAPS中实现了五个优化策略，在后文中会着重阐述。

缓存的优化问题可以被概括为一句话：给定一个优化目标，找到一个最优分配。但是在CAT技术下的优化问题将面临更大的挑战。相比于过去不考虑部分重叠和位置的分配问题，CAT下的分配拥有极其巨大的搜索空间。之前的优化算法只需要决定每个线程需要被分配多少缓存空间，而CAT下需要决定每个分配是从哪到哪，而且还允许部分重叠。搜索整个解空间显然是不现实的，在时间和空间开销上都是不被允许的。可以证明，在这种情况下找到一个最优分配是一个NP-hard问题。

因此，我们的算法并不寻求全局最优分配，而是只需要求解一个较优解。事实上，由于预测的准确率并不十分精确，所以一个全局上的绝对最优解并没有太大意义，反而在短时间内找到一个较优解有更大的意义。为此，我们从经典的模拟退火算法中吸取智慧，构建了一个基于“模拟退火”的优化算法。我们的实验表明该算法在任何优化目标下都能起到良好的效果，具体实验评估结果见第\ref{chap:evaluation}章。

\section{优化目标} \label{sec:opt_goals}

优化的目标是一个优化策略锚定的指标，是驱动一个优化算法的重要动力。一个优化指标是对系统的总体优化目标的一个量化，不同的指标侧重点也不同，总的来说可以被概括为三个方面：性能（Performance）、公平（Fairness）和服务质量（QoS）。当然，一个指标也可以兼顾两个方面，但同时兼顾三个方面是不现实的~\parencite{hsu2006communist}。优化策略的目标就是将锚定的指标最小化或最大化，同时该指标也用来评估策略的有效性。

前人的研究中提出了许多指标来抽象多个并发程序的整体效能。这些指标大多依赖于IPC和失效率这两个参数，这也是CAPS预测模型会输出这两个参数的原因之一。我们希望我们的优化策略具有灵活性，可以很容易适应多个指标，而不用对不同的指标设计截然不同的策略。事实上，因为预测模型预测出了失效率和IPC，只要是基于这两个参数的指标，我们的优化策略都可以直接适配。在本文中，我们选择实现了五个指标作为样例。这五个指标涵盖了各种场合下的优化需求，包括上述所说的性能、公平和服务质量这三个方面。

我们在CAPS中实现的五个指标为：

\begin{itemize}

\item \textbf{平均失效数（Average MPKI）：}平均失效数Average MPKI代表平均每1000条指令的失效数（Misses Per 1000 Instructions, MPKI)。MPKI是系统评估中的常用指标之一，平均失效数代表所有并发程序的平均MPKI，它可以体现出该并发系统的缓存利用效率。较小的平均失效数意味着较高的缓存利用效率，所以针对该指标的优化策略目的就是让平均MPKI尽可能的小。另一方面，LLC缓存失效就意味着该访存指令需要访问内存，所以最小化MPKI也意味着降低内存总线的竞争。在下述公式中，我们定义$MissRate_i$为程序$i$在和别的程序并发执行时的失效率，$APKI_i$是程序$i$每1000条指令的访存指令数。Average MPKI是一个越小越好的指标。

\begin{equation}
AverageMPKI = \sum ( MissRate_i \times APKI_i ) / \#program
\label{eq:mn}
\end{equation}
	
\item \textbf{吞吐量（Throughput）：}吞吐量Throughput被定义为所有程序的IPC之和，这也是一个被广泛使用的指标。针对该指标的策略力求让系统整体的IPC吞吐量最大化。它把所有并发程序看成一个整体，使得整个系统的执行效率最高。但是同时，该指标可能会对一些本身IPC就比较低的程序不太公平，因为降低它们的IPC并不会对整体系统的IPC之和产生非常大的影响。在下述公式中，我们定义$IPC_i$为程序$i$在并发负载中的IPC。Throughput是一个越大越好的指标。

\begin{equation}
	Throughput = \sum IPC_i
	\label{eq:IPCsum}
\end{equation}

\item \textbf{平均效率下降（Average slowdown）：}平均效率下降Average slowdown代表着在平均情况下，程序的在共享LLC与独占LLC的执行时间之比。因为相比于一个程序独占LLC，共享的情况下或多或少都会受到一定的性能损失，所以每个程序的Slowdown一定是大于1的，平均Slowdown自然也大于1。我们定义对于程序$i$来说，它的Slowdown为$SingleIPC_i/IPC_i$，这里$SingleIPC_i$指的是当它单独运行使用全部LLC时每周期执行的指令数（IPC），$IPC_i$是在多程序并发负载中的IPC。平均Slowdown的概念与前人研究中多次提到的另一个指标，加权效率提升（Weighted speedup），有很大相似之处~\parencite{snavely2000symbiotic,qureshi2006utility}。Weighted speedup把并发执行的程序看成一个整体，使用speedup，这个slowdown的倒数，来概括这个整体因为并发带来的效率提升。但是我们认为，每个并发的程序还可以看作独立的个体，每个程序执行各自不同的任务，这样的话针对单个程序的slowdown更可以反映出程序的执行效率，因为共享LLC势必会导致性能下降，所以一定会引起每个程序或多或少的Slowdown，我们把所有程序的Slowdown做算术平均，就可以得到该并发负载因为竞争LLC导致的整体性能下降。Average slowdown是一个越低越好的指标。

\begin{equation}
	AverageSlowdown = \sum\frac{SingleIPC_i}{IPC_i} / \#program
\end{equation}

\item \textbf{公平效率下降（Fair slowdown）：}公平效率下降指标Fair slowdown兼顾了整体性能和公平性。这个指标借鉴了多个前人的研究经验~\parencite{luo2001balancing, chang2014cooperative}。如果只考虑公平性而无视性能是没有意义的，因为大家效率都很差的话，即使再公平也意义不大。我希望通过指标能在提升性能的基础上兼顾公平。与上一个指标Average slowdown不同之处在于，本指标被定义为各个程序Slowdown的调和平均。调和平均鼓励大家的相差尽量小，使得各个程序的slowdown得到均匀的改善。Fair Slowdown是一个越小越好的指标。

\begin{equation}
	FairSlowdown = \#program / {\sum\frac{IPC_i}{SingleIPC_i}}
\end{equation}

\item \textbf{最大效率下降（Maximum slowdown）：}最大效率下降Maximum slowdown指代所有并发程序中的slowdown最大的那一个，它兼顾了性能与服务质量（QoS）。事实上，QoS是比较难以被量化的，因为判断哪些程序优先级较高、哪些程序优先级较低本身就比较主观。在本文中，我们不讨论程序间优先级不同这一主观因素，我们把并发负载看成一个木桶，把QoS定义成木桶中最短的那块短板，也就是Slowdown最高的那个程序。这种表达QoS的方法也被之前的研究者所使用~\parencite{manikantan2012probabilistic}. Maximum slowdown是一个越小越好的指标。

\begin{equation}
MaxSlowdown=\max(\frac{SingleIPC_i}{IPC_i})
\label{eq:qos}
\end{equation}

\end{itemize}

\section{优化算法}

在本节中，我们将介绍CAPS生成优化分配的算法。一个CAT分配组合包含对每一个核/线程的分配所构成的集合，每一个分配可以是20个缓存路中任意一段连续的分配。我们的目标是找到一个最优或较优分配，使得给定的优化指标最大或最小化。之前研究面对的分配问题只需要决定分配的数量，而CAT下由于要求分配是连续的且允许部分重叠，所以分配的位置也需要被考虑进去。

CAT下的优化算法主要存在两点挑战：

首先，搜索空间随着核数增加而呈指数级增长，当核数较多时解空间会变得极其巨大。举例来说，对于20路的缓存，一共有210（1+2+3+..+20）种CLOS，或者说是可能的分配情况。对于一个$N$核的工作负载，$N$个程序并发执行，那么一共可能的CAT分配数为$210^N$。在4核情况下，解空间的规模就已经达到了1,944,810,000，全部搜索一遍显然是不太现实的，甚至搜索一小部分都要耗费大量的时间。

其次，之前的优化分配解决方案都不能适用于CAT。为了避免搜索的时间消耗，之前的解决方案多是通过启发式算法来找优化分配，例如贪心算法~\parencite{suh2004dynamic}、前瞻算法~\parencite{qureshi2006utility}等。但这些解决方案都有一个隐含的假设，就是一个缓存路只能分配一个核，并不能被两个或多个核所共有。这个假设在它们的分配技术下是成立的，然而在CAT下并不成立。所以这些解决方案都不能直接套用在CAT上。

因此，我们需要一个全新的算法来解决CAT下的分配优化问题。我们从经典算法中吸取经验，设计了一个基于模拟退火（Simulated Annealing）的算法，它可以针对任意优化目标生成一个优化分配方案。模拟退火算法是一个随机化算法，它可以在一个庞大的解空间中找到一个全局近似最优解~\parencite{aarts1988simulated,hwang1988simulated}。该算法适合被应用在搜索空间较大并且离散的情况下，CAT优化问题的搜索空间正符合这一特征。同时，模拟退火适合在有限时间内找到一个近似最优解，而不是全局最优解。在CAT优化问题中，短时间内找一个优化解确实比花费大量时间找到一个全局绝对最优解有更大的意义。综上，模拟退火算法是CAT优化问题的一个有效的解决思路。

\begin{algorithm}
\caption{优化算法伪代码}
\label{alg:opt}
\begin{algorithmic}[1]
\renewcommand{\algorithmicforall}{\textbf{foreach}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE concurrent programs and a metric function
\ENSURE a near-optimal CAT scheme
\STATE Profile $MRC[i][]$ and $API[i]$ for each program $i$
\STATE Initialize temperature $T$ and a random allocation $scheme$
\STATE $IPC[]$,$MissRate[]$ = Predict($scheme$)
\STATE $metric$ = CalculateMetric($IPC[]$,$MissRate[]$)
\WHILE {$T < T_{min}$}
	\STATE $scheme'$ = RandomNeighbor($scheme$)
    \STATE $IPC[]$,$MissRate[]$ = Predict($scheme'$)
    \STATE $metric'$ = CalculateMetric($IPC[]$,$MissRate[]$)
    \IF {$metric'$ is better than current $bestMetric$}
    	\STATE $bestMetric$ = $metric'$ 
        \STATE $bestScheme$ = $scheme'$
    \ENDIF
    \IF {$metric$ is lower-is-better}
    	\STATE {$diff$ = $metric'$ - $metric$}
    \ELSE
    	\STATE {$diff$ = $metric$ - $metric'$}
    \ENDIF
    \IF {$diff$ < 0 \OR $\exp(-diff / (k * T)) \leq Random(0,1)$ }
    	\STATE {$metric$ = $metric'$}
        \STATE {$scheme$ = $scheme'$}
    \ENDIF
    \STATE $T$ = $T$ * $TemperatureReductionRatio$
\ENDWHILE
\STATE \textbf{return} $bestScheme$

\end{algorithmic}
\end{algorithm}

CAPS的优化算法伪代码如算法\ref{alg:opt}所示。整个算法过程可以看作在所有CAT分配构成的解空间中的随机游走。我们随机生成的一个CAT分配组合作为游走的起始节点。每一轮，本算法从两个决策中选择一个执行：停留在当前节点，或者走到一个相邻节点。我们认为两个分配组合是相邻的，当且仅当这个两个分配组合中只在某一个核的分配上相差一个缓存路的配额。

不同于爬山算法（Hill Climbing Algorithm）每次都往更好的方向走，模拟退火算法有可能会朝更差的方向走。爬山算法的劣势在于会陷入局部最优解，只能找到最近的山顶而不是全局的山顶。另一方面，模拟退火算法由于允许往更坏的节点走，就会跳出局部的小山，从而找到别处更高的山峰。

我们的算法从随机生成的初始分配组合出发，每次会从当前节点的分配组合中，随机选一个核的分配，然后随机从该分配中的左边和右边选择一边，再随机决定加一个路或减一个路，这样来随机生成一个相邻的分配组合，作为下一步的潜在节点进行考察。值得一提的是，随机生成的邻居分配组合必须是合法的，换句话说说该组合内的每个核的配额都必须大于等于0且小于等于总的路数。

考察的方法，就是将该分配组合输入到上一章介绍的推荐模型中，从而估计得到每个程序的失效率和IPC参数。这两个参数用来计算得到优化指标的值，这里的优化指标具备灵活性，只要是基于失效率和IPC的指标都可以被该算法所接受。比如说，对于IPC吞吐量这个指标，我们就将预测得到的每个程序的IPC相加。

得到邻居分配的指标后，我们将该指标与当前节点的指标相比较，看是更好了还是更坏了。如果邻居节点更好，算法将会无条件走到这个节点上。如果邻居更差，那么算法还是有一定的概率会走向这个节点。这个概率跟当前的“温度”有关，这也是模拟退火算法的精华之处。简而言之，在温度较高时，有更大的概率走向更差的节点，而在温度较低时，走向较差节点的概率更小。温度正是模拟了金属退火的降温冷却过程。初始温度较高，走动随机性更强，而随着温度逐渐降低，走动会越来越偏向于往更优的方向走。这种游走方式可以有效地防止陷入到局部最优解中。

具体来说，算法中允许走到更差节点的概率与选定的指标是越小越优还是越大越优有关。对于越小越优的指标，接受一个较差移动的概率为$\exp(-\Delta e / (kT))$；而对于一个越大越优的指标，该概率为$\exp(\Delta e / (kT))$。这里的$\Delta e$指的是待考察的邻居节点与当前节点的指标差额，$k$是一个可以控制的常量参数，$T$是当前的温度。通常，温度$T$的变化会由一个单调递减函数决定。

常量参数$k$的选取，以及$T$的变化函数，对算法的执行时间和有效性都有较大影响。越高的初始温度，越慢的下降速度，越大的$k$，会带来更大的随机性，会搜索到更多的节点，所以也更可能搜索到更优的结果。但同时，时间的开销也会增加。为了平衡算法的效率和效果，我们通过大量的实验选择了合适的参数和温度变化函数，使得算法可以在短时间内找到一个比较好的解。具体的实验评估结果会在下一章给出。