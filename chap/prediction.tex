% Copyright (c) 2014,2016 Casper Ti. Vector
% Public domain.

\chapter{预测模型} \label{chap:prediction}
\section{模型概述}
在本章中，我们将介绍CAPS的预测模型。对缓存失效率的预测是优化的基础，它的准确性会直接影响到整个优化框架的效果。由于优化决策依赖于预测模型提供的信息，不准确的预测结果可能会导致错误的分配决策。虽然前人对失效率预测进行了大量工作，但它们都不适用于CAT下的预测。因为允许部分共享，分配间可以部分重叠，这就大大增加了预测的难度。为了应对部分重叠的问题，我们为CAPS推导了一个全新的预测模型。

CAPS预测模型可以较为准确地预测出，多个并发执行的程序在任意CAT分配下，每个程序的缓存失效率（Miss Rate）和周期指令数（IPC）。一个CAT分配包括每个线程/核的分配（CLOS）的集合。CAPS预测模型的输入包括每个并发程序的失效率曲线（Miss Rate Curve，MRC）和访存指令占比（Accesses per Instruction, API），以及加载于它们身上的CAT分配。MRC和API可以描绘出一个程序的局部性和缓存访问频率等特征，这两个指标都可以通过离线采样分析得到，在第\ref{sec:prediction_sample}节中会详细介绍。MRC刻画了失效率随缓存大小变化的情况，它是描述某个程序的缓存敏感度的一种有效手段。MRC是这样一条曲线，它的横轴是缓存占用，纵轴是失效率。API用来刻画程序的访存频率，它代表了程序对缓存的污染程度，通常访存频率越高，在竞争中越容易占据较多的缓存空间。

因为CAT分配下，一个程序的缓存分配可能会与一个或多个其他程序的分配部分重叠，每个重叠部分就处于竞争使用状态，所以预测的关键在于弄清楚这些重叠部分的竞争结果，即程序在竞争下实际得到的缓存大小。我们通过一个迭代算法解决了这一问题，算法会在第\ref{sec:prediction_iteration}节中详细阐述。算法中的每次迭代相当于模拟一小段时间片中每个程序执行了一定的指令，在这个过程中，它们的缓存占用发生了改变。我们假设每个程序的访存模式都是稳定的，所以在均衡状态下，各个程序的缓存占用量也会达到稳定，这个稳定值就是我们需要的答案。根据真实占用和MRC很容易推导出每个程序的失效率，再根据失效率估计出IPC，就得到了模型的输出。值得一提的是，实际中每个程序的访存模式都会随着运行阶段的变化而变化，CAPS预测模型也可以适应于这种变化，但是需要在线的实时MRC采样。在本文中，我们只关注程序的平均性能，所以只使用离线采样的平均MRC和API作为输入。

在我们对4到15个程序的工作负载进行了多达750次实验，结果表明CAPS预测模型具有较高的预测准确率，同时还能保持较低的额外开销，具体的实验评估见第\ref{chap:evaluation}章。


\section{离线采样分析} \label{sec:prediction_sample}
本节中，我们将介绍如何通过PIN这一工具离线采样得到程序的MRC和API。研究者们对于如何获取MRC进行了大量的研究，在CAPS中，我们借鉴了基于平均失效时间（Average Eviction Time，AET）的技术~\parencite{hu2016kinect}。任何MRC采样技术都需要程序的访存序列，它是构建MRC的基础。在本文中，我们使用PIN~\parencite{luk2005pin}这一工具对访存序列进行追踪。

Pin是一款针对x86 指令系统的二进制代码分析工具（Binary Instrumentation Tool）。它能够在不改变原有程序执行逻辑的前提下，在该程序的任何指令前后插入用户自定义的代码片段。Pin 包含引擎（PinEngine）和工具（PinTools）两个部分。PinEngine是一个不开源的可执行程序，是其核心部分，它负责完成二进制代码解析和改写。PinTools是由用户自己编写的一些函数库，定义了代码替换的具体规则、以及要插入的代码片段。当Pin执行时，PinTools 会以模块的形式被动态链接到PinEngine中，二者协同完成整个代码替换。

Pin与AET结合构建MRC的工作流程如下：
\begin{enumerate}
\item 被测试的基准程序作为输入被Pin 引擎读入翻译缓存，PinEngine 对它的二进制代码进行静态分析，标记出函数、基本块等；
\item 完成一批代码分析后，PinEngine 会自动调用PinTools 中注册的代码替换回调函数（Instrumentation Callback）。该函数根据用户自己的需要，扫描Pin分析出来的指令流，再调用PinEngine提供的代码替换接口，将自定义的指令回调函数（Execution Callback）插入到程序的指令流中。本例中，我们在所有访存指令之前加入了自己的代码filter\_memop(ip, ea)；
\item PinEngine 将修改后的代码片段载入其执行缓存，并跳转执行它。
\item 执行到访存指令时，修改后的代码片段自动调用先前插入的指令回调函数filter\_memop()，且PinEngine会计算出该指令的指令指针ip和被访问的内存地址ea，作为参数传递给回调函数。在少数情况下，如果该代码片段试图跳转到未翻译的程序代码，则Pin将获得控制权，并跳回步骤2。
\item filter\_memop()的行为非常简单，它只是将ip和ea两个参数放入存放访存序列的缓冲区中（图中的Memory Trace），并返回步骤4继续执行代码片段。只有当缓冲区将要溢出时，才跳转到步骤6。
\item 当被测试的基准程序执行完毕或执行到指定时间点后，输出访存序列和访存指令占比（API）。
\item 利用AET方法，输出最终的缓存失效曲线MRC。
\end{enumerate}

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.8\linewidth]{figures/pin.png}
    \caption{利用Pin和AET构建MRC的流程图}
    \label{fig:pin}
\end{figure}

AET是一个先进的MRC采样技术，它可以在很低的时间空间开销下根据访存序列得到一个准确的MRC。虽然额外开销对于离线优化框架来说并没有那么重要，但我们仍然想控制时空开销，因为我们计划在未来将CAPS拓展到在线环境中。AET具有线性的时间复杂度，并且可以通过随机采样来减少运行时间，同时也能保持较高的MRC准确率。

\begin{figure}[htbp] 
    \centering
    \includegraphics[width=0.8\linewidth]{figures/AET_overhead.png}
    \caption{AET与其他技术的时间与空间开销对比}
    \label{fig:AET_overhead}
\end{figure}

以往的MRC技术多是基于重用距离，它被定义为对同一数据的相邻两次访问间所间隔的不同数据数。通过构造出重用距离直方图，然后累加得到MRC。但是完整地统计出重用距离直方图会带来巨大的时间和空间开销。从渐进意义上来说，对于$N$个读写访问到$M$个不同的地址，构造重用距离直方图的时间复杂度为$O(N\log M)$，空间复杂度为$O(M)$~\cite{olken1981efficient}。

基于AET的方法引入了平均失效时间（Average Eviction Time，AET）这一概念。失效时间（Eviction Time）被定义为最近一次访问到失效所经历的时间。LRU缓存可以被看作是一个栈，栈中数据按最近访问时间排序。最近访问多的在栈顶，最近访问少的在栈底。栈底被挤出去的就是被替换掉了。AET实际上就是缓存块从栈顶移动到栈底并出栈的平均时间。AET模型的输入是重用时间而不是重用距离，两者的差别在于，前者并不需要统计两次重用之间不同的访问次数，只需要统计总次数，所以可以通过随机采样的方式大大减少时间和空间消耗，因为只要采样的重用时间分布与真实的分布一样，AET一样可以得到准确的MRC。通过随机采样一小部分的访存，大量的时间和空间开销可以被节省下来。下面我们来推导AET模型。

我们设$T_m$是一个数据块在到达LRU栈的位置$m$的平均时间。显然，$T_0=0$ and $\textit{AET}(c) = T_{c}$。注意这里是所有数据块的平均情况。

设$n$是所有访存总数，$rt(t)$是重用时间为$t$的访存数量。$f(t)$是重用时间为$t$的访存占比。则：

\begin{equation}
f(t) = \frac{rt(t)}{n}
\label{eq:aet_f}
\end{equation}

对于一个访存来说，$P(t)$是它的重用时间大于$t$的概率：

\begin{equation}
P(t) = \sum_{t+1}^{\infty}f(t)
\label{eq:aet_rt}
\end{equation}

现在数据块向LRU栈底部的每次移动可以被视为一个概率事件。从另一个角度，也可以理解成在单位时间数据块向下移动了$P(t)$。这可以理解为移动的速度，在位置$m$，平均达到时间为$T_m$，则平均速度$v(T_m)$为：

\begin{equation}
v(T_m) = P(T_m) 
\label{eq:aet_vm}
\end{equation}

将速度做积分，就可以得到移动的距离。事实上，$x$从0积分到$\textit{AET}(c)$，就是缓存的大小，所以有如下公式：

\begin{equation}
\int_0^{AET(c)} P(x) dx = c
\label{eq:aet_aet}
\end{equation}

该公式可以这样被证明：

\begin{align}
\begin{split}
 & \sum_{m=0}^{c-1} {\int_{T_m}^{T_{m+1}} (v(T_m) - \sum_{t=T_m}^{x-1}f(t))} dx \nonumber\\
 &= \sum_{m=0}^{c-1} {\int_{T_m}^{T_{m+1}} (P(T_m) - \sum_{t=T_m}^{x-1}f(t))} dx \nonumber\\
&= \sum_{m=0}^{c-1} {\int_{T_m}^{T_{m+1}} (P(T_m) - (P(T_m) - P(x)))} dx  \nonumber\\
&= \sum_{m=0}^{c-1} {\int_{T_m}^{T_{m+1}} P(x)} dx  \nonumber\\
&= \int_{T_0}^{T_1} P(x) dx + \int_{T_1}^{T_2} P(x) dx\nonumber\\
&\quad ...  + \int_{T_{c-1}}^{T_c} P(x) dx \nonumber\\
&= \int_0^{AET(c)} P(x) dx \nonumber
\end{split}
\end{align}

根据AET，很容易构造出MRC。因为在缓存大小$c$时的失效率，就是重用时间大于$\textit{mr}(c)$的概率。MRC构造公式如下：

\begin{equation}
mr(c) = P(AET(c)) 
\label{eq:aet_mrr}
\end{equation}

综上，我们就得到了一个高效的MRC构造方法。对于部分共享的情况，只有MRC是不够的，下一节我们将介绍如何通过一个迭代算法来求解重叠情况下的预测问题。

% 在步骤6 中，计算重用距离需要知道与上次访问该地址之间间隔的不同地址的
% 数目。这需要用一个散列表记住所有访问过的内存地址，然后用链表将它们串起，
% 在软件中模拟LRU 队列的行为。由于程序的访存操作数以百亿计，优化这一算法
% 是十分必要的。本文采用了文献[56]中提到的树算法来加速重用距离的近似计算。

\section{迭代预测算法} \label{sec:prediction_iteration}

在分配没有重叠的情况下，得到MRC就完成了预测。因为分配的大小就是某个程序独自占用的的实际大小，根据MRC就可以直接得到失效率。此外，还有一些研究针对完全重叠的情况进行预测~\parencite{chandra2005predicting, suh2014analytical, xiang2011all, xiang2011linear, hu2016kinect}。然而，它们都不能适用于CAT下的部分重叠分配。简单地把部分重叠分配下的每个完全重叠片段看成是一个自由竞争的小缓存块是不正确的。因为CAT是通过缓存失效来驱动的，在CAT下，如果是一个缓冲命中，那么它可以命中在LLC的任何地方，即使是在这个核的分配之外，此时CAT不发挥作用。CAT只在缓存失效时才发生作用，此时该失效只能替换掉发起这个请求的核的分配之内的缓存。所以，对于某个核来说，它发出的访问请求并不是均匀分布在它的分配中，而是它引起的失效均匀分布到它的分配中。因此，我们并不能脱离整体，而把每个完全竞争的缓存块当成一个独立的完全共享的缓存，而应该在整体上关注真实的缓存占用。

 为此，我们推导了一个全新的模型，通过迭代来预测部分重叠情况下的缓存占用和失效率。首先，我们根据每个分配的起点和终点，将整个缓存空间划分成多个缓存段。每个缓存段是一个完全重叠子区域，它们组合在一起构成整个LLC。显然，总的缓存段数小于等于总的路数，因为最多情况下每一路都是不同的缓存段。分段过后，每个程序的分配区域可以被看成几个连续的缓存段。在每个缓存段中，分配中包含这段的程序互相竞争。我们预测算法的基本思路是，通过计算每一个缓存段中各个程序的实际占用，将它们汇总就可以得到总的真实占用。为此，我们需要搞清楚每个缓存段的竞争结果，才能知道每个程序的实际占用。

 某程序占用的缓存大小和它造成的失效数息息相关，因为正是失效导致的替换抢夺了缓存空间。失效数与缓存占用同时存在着正向和负向两种关系。失效数越多，意味着更多的缓存占用，但另一方面，更多的缓存意味着更少的失效。这种关系类似控制论中的负反馈概念，最后会达到一个稳定的状态。这个稳定状态就是我们要求的状态。假设程序的访存模式是很定的，那么稳定状态时的缓存占用和失效率就是真实的占用和失效率。CAPS预测模型通过一个迭代算法求出这个稳定状态，算法伪代码如算法\ref{alg:pred}所示。

\begin{algorithm}
\caption{Prediction Algorithm}
\label{alg:pred}
\begin{algorithmic}[1]
\renewcommand{\algorithmicforall}{\textbf{foreach}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE $MRC[i][]$ and $API[i]$ of each program $i$; a CAT scheme
\ENSURE $MissRate[i]$, $IPC[i]$ for each program $i$
\STATE Partition cache space to shared intervals based on allocations' starting and finishing points
\STATE Initialize $occupancy[i][j]$ for program $i$ in interval $j$ = (size of interval $j$) / (number of programs sharing the interval)
\WHILE {aggregate change of occupancies > threshold}
	\STATE {/* occupancy to miss rate */}
    \FORALL {program $i$}
    	\STATE $occ$ = $0$
    	\FORALL {interval $j$}
			\STATE $occ$ += $occupancy[i][j]$
        \ENDFOR
        \STATE $MissRate[i]$ = $MRC[i][occ]$
        \STATE $IPC[i]$ = $1 / (CPI_{base} + MissRate[i] * API[i] * MissPenalty)$
        \STATE $Miss[i]$ = $MissRate[i] * API[i] * IPC[i] * step$
    \ENDFOR
    \STATE {/* miss rate to occupancy */}
    \FORALL {interval $j$}
    	\STATE $TotalIntervalMiss$ = $0$
   		\FORALL {program $i$ in interval $j$}
        	\STATE $IntervalMiss[i][j]$ = $Miss[i] * IntervalSize[j] / AllocationSize[i]$
            \STATE $TotalIntervalMiss$ += $IntervalMiss[i][j]$ 
		\ENDFOR
        
        \FORALL {program $i$ in interval $j$}
        	\STATE $occupancy[i][j]$ =  $occupancy[i][j] + IntervalMiss[i][j] * (IntervalSize[j] - occupancy[i][j]) / IntervalSize[j] - (TotalIntervalMiss - IntervalMiss[i][j]) * occupancy[i][j] / IntervalSize[j]$
		\ENDFOR
    \ENDFOR
    \IF {$step$ > $minStep$}
    	\STATE $step$ = $step * StepReductionRatio$
    \ENDIF
\ENDWHILE

\STATE \textbf{return} $MissRate[]$, $IPC[]$

\end{algorithmic}
\end{algorithm}

我们默认每个程序的MRC和API已经得到。该算法的目标是通过迭代过程得到稳定状态下的实际缓存占用。得到实际缓存占用后，很容易通过MRC得到失效率，然后可以估计出IPC。作为迭代的初始状态，我们首先需要给出一个初始占用。这个占用可是随机的，并不影响最后的结果，但是会影响迭代收敛的速度。在CAPS中，我们在每个完全共享的缓存段中使用平均分配作为初始占用。在每次迭代中，我们先根据当前的占用结果计算得到失效率，然后我们再根据当前的失效率推导出下一阶段的占用。直到变化的程度小于一定的阈值，我们认为迭代收敛，此时的占用即是我们要求的稳定状态下的真实占用。

我们引入了一个迭代步长参数$Step$来控制收敛过程。$Step$模拟在冷启动中每次迭代的步长，它也可以被看成公式\ref{eq:accesses}中的周期数。更大的步长通常意味着更快的收敛速度，但是同时也可能造成某次迭代越过了均衡点，导致迭代在均衡点两侧跳动从而无法收敛。另一方面，较小的步长可能会影响收敛速度，降低预测算法的效率。在CAPS中，我们选择了一个较大的初始$Step$，然后逐渐地降低它，每轮迭代降低5\%，直到设定的最低点。这样的话，我们可以在保证收敛到均衡点的同时提升了收敛速度。

下面我们将列出并阐述了预测模型中重要的公式。每轮迭代前半部分通过当前轮的缓存占用来推导失效率、失效数和IPC。这主要涉及到以下两个公式：

\begin{equation}
Misses = MissRate \times API \times IPC \times Step 
\label{eq:accesses}
\end{equation}

\begin{equation}
IPC = \frac{1}{CPI_{base} + API \times MissRate \times MissPenalty}
\label{eq:IPC}
\end{equation}

上一节的离线采样我们已经得到了每个程序的$MRC$，根据当前的缓存占用直接查阅MRC就可以得到失效率$MissRate$。有了$MissRate$可以根据公式\ref{eq:accesses}计算得到失效数$Misses$。而$IPC$比较难以估计，因为很多因素都可以影响到IPC。这里，我们通过公式\ref{eq:IPC}来做一个近似估计。$CPI_{base}$和$MissPenalty$通过真实机器上的实验来估计。$CPI_{base}$通过一个失效率很低的小benchmark来估计，而$MissPenalty$通过LLC的失效延迟来估计。   

注意，公式\ref{eq:accesses}得到的是该程序总的失效数。因为英特尔处理器使用特殊的哈希函数来处理内存地址到LLC的映射，所以这些失效可以被认为在分配区域内随机分布，换句话说分布是均匀的。某个小缓存段中产生的失效占总体失效数的比例与它的大小占比是相同的。根据总的失效数和小缓存段大小占该程序分配区域的比例，就可以就可以得到每个缓存段的失效数。

每轮迭代的后半部分，我们通过当前的失效数和IPC，来更新缓存占用情况。对于每个缓存段，我们各个击破，因为每个缓存段的竞争情况都是不同的。那么如何根据失效数和IPC来推导新的缓存占用呢？West等在一篇论文中介绍了一种双线程下缓存占用实时预测的方法\parencite{west2010online}，该研究是通过硬件实时抓取到失效率来预测两个线程的缓存占用情况。虽然使用场景与我们的场景并不相同，但也有很多共通之处。我们受其启发，建立了一个类似的定理用来计算多个程序的缓存占用。为了简化模型，我们假设所有程序都是单线程的，且在不同的核上执行。

\textbf{定理：}\emph{考虑一个容量为$C$的LLC，被$N$个并发程序锁共享。每个程序目前分别占用了$C_1, C_2, ... , C_N$ 的缓存大小，并且在这一阶段分别产生了$M_1, M_2, ... , M_N$个失效。设$M$为失效数的总和，则对于程序$i$来说，它更新后的缓存占用为：$C_i' = C_i + \frac{C-C_i}{C} \cdot M_i - \frac{C_i}{C} \cdot (M-M_i)$.}

\textbf{证明：}首先，我们假设整个LLC空间已经被这$N$个程序充满。事实上，除了冷启动外，绝大多数时间LLC都是被充满的。这时，如下公式成立：

\begin{equation}
C = \sum_{i=0}^{N} C_i
\label{eq:sumc}
\end{equation}

其次，我们假设每个缓存块都有均等的概率被替换。虽然在LRU策略下，这个假设通常是不正确的。失效的访存会替换掉最近最少被使用（least-recently-used）的那个缓存块，这就意味着经常被访问的缓存块被替换的概率较小。然而，为了模型简洁性，我们仍然使用这一假设。事实上，这一假设不会给准确率带来很大影响\parencite{west2010online}。

当程序$i$发生了一个失效时，它替换掉的缓存块属于其他程序的概率为：$\frac{C-C_i}{C}$，这就相当于把缓存块从其他程序那里抢夺过来。程序$i$在单位时间内总共产生了$M_i$个失效，所以因为失效而抢夺过来的缓存块数量为：$\frac{C-C_i}{C} \cdot M_i $。在另一方面，其他程序的失效也可能从它这里抢夺一部分缓存块。一个缓存块属于程序$i$的概率为$\frac{C_i}{C}$，其他程序产生的失效数为$(M-M_i)$，所以其他程序从它这里抢夺的缓存块数量为：$\frac{C_i}{C} \cdot (M-M_i)$。在这个阶段过后，该程序占用的缓存块数量变动即为，抢夺来的缓存块减去被抢夺走的缓存块：

\begin{equation}
 \Delta C = \frac{C-C_i}{C} \cdot M_i - \frac{C_i}{C} \cdot (M-M_i)
 \label{eq:deltac}
\end{equation}

更新后的缓存占用为：

\begin{equation}
 C_i' = C_i + \frac{C-C_i}{C} \cdot M_i - \frac{C_i}{C} \cdot (M-M_i)
 \label{eq:occupancy}
\end{equation}

更新后的缓存占用仍然符合公式\ref{eq:sumc}，所有$C_i'$之和仍然为$C$。在CAPS预测模型中，我们对于某个缓存段，使用公式\ref{eq:occupancy}计算每轮迭代更新后的缓存占用。然而将所有缓存段的占用加总，就得到了该程序在当前迭代轮的总缓存占用。此时就完成了一轮迭代。当缓存占用的变化率小于一定的阈值后，我们认为迭代已经收敛，我们要求的稳定状态已经达到。此时，模型输出每个程序预测的失效率和IPC。